login as: cloudera
cloudera@192.168.252.128's password:
Access denied
cloudera@192.168.252.128's password:
Last login: Thu Aug  8 20:04:17 2019 from 192.168.252.1
[cloudera@quickstart ~]$ hive

Logging initialized using configuration in file:/etc/hive/conf.dist/hive-log4j.p                                                                             roperties
WARNING: Hive CLI is deprecated and migration to Beeline is recommended.
hive> ls
    > [cloudera@quickstart ~]$
[cloudera@quickstart ~]$ hive

Logging initialized using configuration in file:/etc/hive/conf.dist/hive-log4j.properties
WARNING: Hive CLI is deprecated and migration to Beeline is recommended.
hive> create database dvs_hive;
OK
Time taken: 3.332 seconds
hive> create database dvs_jul19;
OK
Time taken: 0.162 seconds
hive> delete database dvs_hive;
Usage: delete [FILE|JAR|ARCHIVE] <value> [<value>]*
Query returned non-zero code: 1, cause: null
hive> drop database dvs_hive;
OK
Time taken: 0.312 seconds
hive> desc database dvs_jul19;
OK
dvs_jul19               hdfs://quickstart.cloudera:8020/user/hive/warehouse/dvs_jul19.db        cloudera        USER
Time taken: 0.429 seconds, Fetched: 1 row(s)
hive> mmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmm
    >
    > ;
NoViableAltException(26@[])
        at org.apache.hadoop.hive.ql.parse.HiveParser.statement(HiveParser.java:1029)
        at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:201)
        at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:166)
        at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:524)
        at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1358)
        at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1475)
        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1287)
        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1277)
        at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:226)
        at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:175)
        at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:389)
        at org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:781)
        at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:699)
        at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:634)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.apache.hadoop.util.RunJar.run(RunJar.java:221)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:136)
FAILED: ParseException line 1:0 cannot recognize input near 'mmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmm' '<EOF>' '<EOF>'
hive> use dvs_jul19;
OK
Time taken: 0.033 seconds
hive> desc database;
NoViableAltException(-1@[])
        at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.identifier(HiveParser_IdentifiersParser.java:11567)
        at org.apache.hadoop.hive.ql.parse.HiveParser.identifier(HiveParser.java:45101)
        at org.apache.hadoop.hive.ql.parse.HiveParser.descStatement(HiveParser.java:17847)
        at org.apache.hadoop.hive.ql.parse.HiveParser.ddlStatement(HiveParser.java:2618)
        at org.apache.hadoop.hive.ql.parse.HiveParser.execStatement(HiveParser.java:1590)
        at org.apache.hadoop.hive.ql.parse.HiveParser.statement(HiveParser.java:1066)
        at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:201)
        at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:166)
        at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:524)
        at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1358)
        at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1475)
        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1287)
        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1277)
        at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:226)
        at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:175)
        at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:389)
        at org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:781)
        at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:699)
        at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:634)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.apache.hadoop.util.RunJar.run(RunJar.java:221)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:136)
FAILED: ParseException line 1:13 cannot recognize input near '<EOF>' '<EOF>' '<EOF>' in describe statement
hive> show databases;
OK
default
dvs
dvs_dec18
dvs_jul19
dvs_mar1
learning
test
Time taken: 0.041 seconds, Fetched: 7 row(s)
hive> cls
    >
    > ;
NoViableAltException(26@[])
        at org.apache.hadoop.hive.ql.parse.HiveParser.statement(HiveParser.java:1029)
        at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:201)
        at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:166)
        at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:524)
        at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1358)
        at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1475)
        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1287)
        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1277)
        at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:226)
        at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:175)
        at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:389)
        at org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:781)
        at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:699)
        at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:634)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.apache.hadoop.util.RunJar.run(RunJar.java:221)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:136)
FAILED: ParseException line 1:0 cannot recognize input near 'cls' '<EOF>' '<EOF>'
hive> clear
    > ;
NoViableAltException(26@[])
        at org.apache.hadoop.hive.ql.parse.HiveParser.statement(HiveParser.java:1029)
        at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:201)
        at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:166)
        at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:524)
        at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1358)
        at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1475)
        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1287)
        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1277)
        at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:226)
        at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:175)
        at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:389)
        at org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:781)
        at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:699)
        at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:634)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.apache.hadoop.util.RunJar.run(RunJar.java:221)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:136)
FAILED: ParseException line 1:0 cannot recognize input near 'clear' '<EOF>' '<EOF>'
hive> cls;
NoViableAltException(26@[])
        at org.apache.hadoop.hive.ql.parse.HiveParser.statement(HiveParser.java:1029)
        at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:201)
        at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:166)
        at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:524)
        at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1358)
        at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1475)
        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1287)
        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1277)
        at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:226)
        at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:175)
        at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:389)
        at org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:781)
        at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:699)
        at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:634)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.apache.hadoop.util.RunJar.run(RunJar.java:221)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:136)
FAILED: ParseException line 1:0 cannot recognize input near 'cls' '<EOF>' '<EOF>'
hive> set hive.cli
hive.cli.errors.ignore            hive.cli.pretty.output.num.cols   hive.cli.print.current.db         hive.cli.print.header
hive.cli.prompt                   hive.client.stats.counters        hive.client.stats.publishers
hive> set hive.cli.print.
hive.cli.print.current.db   hive.cli.print.header
hive> set hive.cli.print.current.db
    > ;
hive.cli.print.current.db=false
hive> set hive.cli.print.current.db = true;
hive (dvs_jul19)> create table emp(empno int,name string,job string,sal double,comm float,deptno int)
                > ;
OK
Time taken: 0.407 seconds
hive (dvs_jul19)> drop table emp;
OK
Time taken: 1.494 seconds
hive (dvs_jul19)> create table emp(empno int,name string,job string,sal double,comm float,deptno int) row format delimited fields terminated by ',';
OK
Time taken: 0.097 seconds
hive (dvs_jul19)> desc emp;
OK
empno                   int
name                    string
job                     string
sal                     double
comm                    float
deptno                  int
Time taken: 0.163 seconds, Fetched: 6 row(s)
hive (dvs_jul19)> create table dept(deptno int,dname string,dloc string) row format delimited fields terminated by ',';
OK
Time taken: 0.103 seconds
hive (dvs_jul19)> desc dept;
OK
deptno                  int
dname                   string
dloc                    string
Time taken: 0.159 seconds, Fetched: 3 row(s)
hive (dvs_jul19)> load data local inpath '/home/cloudera/dvs/emp.csv' into table emp;
Loading data to table dvs_jul19.emp
Table dvs_jul19.emp stats: [numFiles=1, totalSize=493]
OK
Time taken: 1.257 seconds
hive (dvs_jul19)> select * from emp;
OK
7369    SMITH   CLERK   800.0   NULL    20
7499    ALLEN   SALESMAN        1600.0  300.0   30
7521    WARD    SALESMAN        1250.0  500.0   30
7566    JONES   MANAGER 2975.0  NULL    20
7654    MARTIN  SALESMAN        1250.0  1400.0  30
7698    BLAKE   MANAGER 2850.0  NULL    30
7782    CLARK   MANAGER 2450.0  NULL    10
7788    SCOTT   ANALYST 3000.0  NULL    20
7839    KING    PRESIDENT       5000.0  NULL    10
7844    TURNER  SALESMAN        1500.0  0.0     30
7876    ADAMS   CLERK   1100.0  NULL    20
7900    JAMES   CLERK   950.0   NULL    30
7902    FORD    ANALYST 3000.0  NULL    20
7934    MILLER  CLERK   1300.0  NULL    10
Time taken: 0.587 seconds, Fetched: 14 row(s)
hive (dvs_jul19)> set hive.cli.print.header=true;
hive (dvs_jul19)> select * from emp;
OK
emp.empno       emp.name        emp.job emp.sal emp.comm        emp.deptno
7369    SMITH   CLERK   800.0   NULL    20
7499    ALLEN   SALESMAN        1600.0  300.0   30
7521    WARD    SALESMAN        1250.0  500.0   30
7566    JONES   MANAGER 2975.0  NULL    20
7654    MARTIN  SALESMAN        1250.0  1400.0  30
7698    BLAKE   MANAGER 2850.0  NULL    30
7782    CLARK   MANAGER 2450.0  NULL    10
7788    SCOTT   ANALYST 3000.0  NULL    20
7839    KING    PRESIDENT       5000.0  NULL    10
7844    TURNER  SALESMAN        1500.0  0.0     30
7876    ADAMS   CLERK   1100.0  NULL    20
7900    JAMES   CLERK   950.0   NULL    30
7902    FORD    ANALYST 3000.0  NULL    20
7934    MILLER  CLERK   1300.0  NULL    10
Time taken: 0.091 seconds, Fetched: 14 row(s)
hive (dvs_jul19)> load data local inpath '/home/cloudera/dvs/emp1.csv' into table emp;
Loading data to table dvs_jul19.emp
Table dvs_jul19.emp stats: [numFiles=2, totalSize=592]
OK
Time taken: 0.422 seconds
hive (dvs_jul19)> select * from emp;
OK
emp.empno       emp.name        emp.job emp.sal emp.comm        emp.deptno
7369    SMITH   CLERK   800.0   NULL    20
7499    ALLEN   SALESMAN        1600.0  300.0   30
7521    WARD    SALESMAN        1250.0  500.0   30
7566    JONES   MANAGER 2975.0  NULL    20
7654    MARTIN  SALESMAN        1250.0  1400.0  30
7698    BLAKE   MANAGER 2850.0  NULL    30
7782    CLARK   MANAGER 2450.0  NULL    10
7788    SCOTT   ANALYST 3000.0  NULL    20
7839    KING    PRESIDENT       5000.0  NULL    10
7844    TURNER  SALESMAN        1500.0  0.0     30
7876    ADAMS   CLERK   1100.0  NULL    20
7900    JAMES   CLERK   950.0   NULL    30
7902    FORD    ANALYST 3000.0  NULL    20
7934    MILLER  CLERK   1300.0  NULL    10
1111    Kavya   SE      1500000.0       5000.0  11
2222    Vinu    SSE     160000.0        6000.0  22
3333    abc     Manager 100000.0        2999.0  NULL
NULL    4444            NULL    NULL    NULL
Time taken: 0.164 seconds, Fetched: 18 row(s)
hive (dvs_jul19)>


login as: cloudera
cloudera@192.168.252.128's password:
Last login: Fri Aug  9 09:38:42 2019 from 192.168.252.1
[cloudera@quickstart ~]$ pwd
/home/cloudera
[cloudera@quickstart ~]$ cd dvs
[cloudera@quickstart dvs]$ ls
1987.csv         emp.csv              people.csv     sample.json
bag.txt          emp.json             pets.csv       sample.xml
b_out            emp.tsv              pig            sqoop_param.txt
bucketsdata.csv  HDFS_directory       piggybank.jar  std
complex          hive                 pigout         TempStatsStore
c_out            hive_assignment.csv  pigout1        test.txt
dept.csv         json                 pigparam       tup.txt
d_out            owners.csv           pigparam1.txt
emp1.csv         param.txt            pigparam.txt
emp3.csv         pass                 sample1.json
[cloudera@quickstart dvs]$ cd ..
[cloudera@quickstart ~]$ ls
cloudera-manager            lib                        sqp.txt
cm_api.py                   metastore_db               start-all.sh
derby.log                   Music                      Start-HDFS.sh
Desktop                     orders1.java               Start-HIVE.sh
Documents                   orders2.java               Start-YARN.sh
Downloads                   orders.java                stop-all.sh
dvs                         parcels                    Stop-HDFS.sh
eclipse                     Pictures                   Stop-HIVE.sh
eclipseScala                pig_1548732591528.log      Stop-YARN.sh
enterprise-deployment.json  pig_1548733222535.log      target
evenorodd.sh                pig_1548814172798.log      Templates
express-deployment.json     pig_1548817949732.log      test.txt
flink-1.5.0                 project                    Videos
IdeaProjects                projects                   workspace
java                        Public                     workspace1
kafka_2.11-0.10.2.1         sbt                        zeppelin-0.7.3-bin-all
kerberos                    spark-2.3.1-bin-hadoop2.6
[cloudera@quickstart ~]$ sh start-all.sh
starting datanode, logging to /var/log/hadoop-hdfs/hadoop-hdfs-datanode-quicksta                                                                             rt.cloudera.out
Started Hadoop datanode (hadoop-hdfs-datanode):            [  OK  ]
starting journalnode, logging to /var/log/hadoop-hdfs/hadoop-hdfs-journalnode-qu                                                                             ickstart.cloudera.out
Started Hadoop journalnode:                                [  OK  ]
starting namenode, logging to /var/log/hadoop-hdfs/hadoop-hdfs-namenode-quicksta                                                                             rt.cloudera.out
Started Hadoop namenode:                                   [  OK  ]
starting secondarynamenode, logging to /var/log/hadoop-hdfs/hadoop-hdfs-secondar                                                                             ynamenode-quickstart.cloudera.out
Started Hadoop secondarynamenode:                          [  OK  ]
Started Hadoop httpfs (hadoop-httpfs):                     [  OK  ]
starting nodemanager, logging to /var/log/hadoop-yarn/yarn-yarn-nodemanager-quic                                                                             kstart.cloudera.out
Started Hadoop nodemanager:                                [  OK  ]
starting resourcemanager, logging to /var/log/hadoop-yarn/yarn-yarn-resourcemana                                                                             ger-quickstart.cloudera.out
Started Hadoop resourcemanager:                            [  OK  ]
starting historyserver, logging to /var/log/hadoop-mapreduce/mapred-mapred-histo                                                                             ryserver-quickstart.cloudera.out
Started Hadoop historyserver:                              [  OK  ]
[cloudera@quickstart ~]$ sh Start-HIVE.sh
Starting Hive Metastore (hive-metastore):                  [  OK  ]
Started Hive Server2 (hive-server2):                       [  OK  ]
[cloudera@quickstart ~]$ cls
-bash: cls: command not found
[cloudera@quickstart ~]$ clear
[cloudera@quickstart ~]$ hive

Logging initialized using configuration in file:/etc/hive/conf.dist/hive-log4j.p                                                                             roperties
WARNING: Hive CLI is deprecated and migration to Beeline is recommended.
hive> create database dvs_hive;
FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTa                                                                             sk. Database dvs_hive already exists
hive> drop database dvs_hive;
FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTa                                                                             sk. InvalidOperationException(message:Database dvs_hive is not empty. One or mor                                                                             e tables exist.)
hive> drop database dvs_hive cascade;
OK
Time taken: 13.448 seconds
hive> create database dvs_hive;
OK
Time taken: 0.484 seconds
hive> desc database dvs_hive;
OK
dvs_hive                hdfs://quickstart.cloudera:8020/user/hive/warehouse/dvs_                                                                             hive.db cloudera        USER
Time taken: 0.498 seconds, Fetched: 1 row(s)
hive> show databases;
OK
default
dvs
dvs_dec18
dvs_hive
dvs_jul19
dvs_mar1
learning
test
Time taken: 0.038 seconds, Fetched: 8 row(s)
hive> use dvs_hive;
OK
Time taken: 0.027 seconds
hive> set hive.cli
hive.cli.errors.ignore            hive.cli.pretty.output.num.cols   hive.cli.print.current.db         hive.cli.print.header
hive.cli.prompt                   hive.client.stats.counters        hive.client.stats.publishers
hive> set hive.cli.print.current.db=true;
hive (dvs_hive)> use default;
OK
Time taken: 0.031 seconds
hive (default)> set hive.cli.print.current.db=true;
hive (default)> use dvs_hive;
OK
Time taken: 0.027 seconds
hive (dvs_hive)> set hive.cli.print.current.db=true;
hive (dvs_hive)> create table(pet name,type name)row format delimited fields terminated by ',';
NoViableAltException(290@[184:1: tableName : (db= identifier DOT tab= identifier -> ^( TOK_TABNAME $db $tab) |tab= identifier -> ^( TOK_TABNAME $tab) );])
        at org.antlr.runtime.DFA.noViableAlt(DFA.java:158)
        at org.antlr.runtime.DFA.predict(DFA.java:144)
        at org.apache.hadoop.hive.ql.parse.HiveParser_FromClauseParser.tableName(HiveParser_FromClauseParser.java:4693)
        at org.apache.hadoop.hive.ql.parse.HiveParser.tableName(HiveParser.java:45138)
        at org.apache.hadoop.hive.ql.parse.HiveParser.createTableStatement(HiveParser.java:4874)
        at org.apache.hadoop.hive.ql.parse.HiveParser.ddlStatement(HiveParser.java:2558)
        at org.apache.hadoop.hive.ql.parse.HiveParser.execStatement(HiveParser.java:1590)
        at org.apache.hadoop.hive.ql.parse.HiveParser.statement(HiveParser.java:1066)
        at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:201)
        at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:166)
        at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:524)
        at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1358)
        at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1475)
        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1287)
        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1277)
        at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:226)
        at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:175)
        at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:389)
        at org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:781)
        at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:699)
        at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:634)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.apache.hadoop.util.RunJar.run(RunJar.java:221)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:136)
FAILED: ParseException line 1:12 cannot recognize input near '(' 'pet' 'name' in table name
hive (dvs_hive)> create table pets(pet name,type name)row format delimited fields terminated by ',';
NoViableAltException(26@[])
        at org.apache.hadoop.hive.ql.parse.HiveParser.type(HiveParser.java:39239)
        at org.apache.hadoop.hive.ql.parse.HiveParser.colType(HiveParser.java:39004)
        at org.apache.hadoop.hive.ql.parse.HiveParser.columnNameType(HiveParser.java:38704)
        at org.apache.hadoop.hive.ql.parse.HiveParser.columnNameTypeList(HiveParser.java:36899)
        at org.apache.hadoop.hive.ql.parse.HiveParser.createTableStatement(HiveParser.java:5058)
        at org.apache.hadoop.hive.ql.parse.HiveParser.ddlStatement(HiveParser.java:2558)
        at org.apache.hadoop.hive.ql.parse.HiveParser.execStatement(HiveParser.java:1590)
        at org.apache.hadoop.hive.ql.parse.HiveParser.statement(HiveParser.java:1066)
        at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:201)
        at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:166)
        at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:524)
        at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1358)
        at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1475)
        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1287)
        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1277)
        at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:226)
        at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:175)
        at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:389)
        at org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:781)
        at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:699)
        at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:634)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.apache.hadoop.util.RunJar.run(RunJar.java:221)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:136)
FAILED: ParseException line 1:22 cannot recognize input near 'name' ',' 'type' in column type
hive (dvs_hive)> create table pets(petname string,typename string)row format delimited fields terminated by ',';
OK
Time taken: 0.387 seconds
hive (dvs_hive)> load data local inpath '/home/cloudera/dvs/pets.csv' into table pets;
Loading data to table dvs_hive.pets
Table dvs_hive.pets stats: [numFiles=1, totalSize=48]
OK
Time taken: 1.831 seconds
hive (dvs_hive)> select * from pets;
OK
nemo    fish
fido    dog
rex     dog
paws    cat
wiskers cat
Time taken: 0.573 seconds, Fetched: 5 row(s)
hive (dvs_hive)>
               > ;
hive (dvs_hive)> load from local inpath '/home/cloudera/dvs/pets.csv' into pets;
MismatchedTokenException(118!=73)
        at org.antlr.runtime.BaseRecognizer.recoverFromMismatchedToken(BaseRecognizer.java:617)
        at org.antlr.runtime.BaseRecognizer.match(BaseRecognizer.java:115)
        at org.apache.hadoop.hive.ql.parse.HiveParser.loadStatement(HiveParser.java:1704)
        at org.apache.hadoop.hive.ql.parse.HiveParser.execStatement(HiveParser.java:1545)
        at org.apache.hadoop.hive.ql.parse.HiveParser.statement(HiveParser.java:1066)
        at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:201)
        at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:166)
        at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:524)
        at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1358)
        at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1475)
        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1287)
        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1277)
        at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:226)
        at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:175)
        at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:389)
        at org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:781)
        at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:699)
        at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:634)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.apache.hadoop.util.RunJar.run(RunJar.java:221)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:136)
FAILED: ParseException line 1:5 mismatched input 'from' expecting DATA near 'load' in load statement
hive (dvs_hive)> load data local inpath '/home/cloudera/dvs/pets.csv' into pets;
FAILED: ParseException line 1:58 missing TABLE at 'pets' near '<EOF>'
hive (dvs_hive)> load data local inpath '/home/cloudera/dvs/pets.csv' into table  pets;
Loading data to table dvs_hive.pets
Table dvs_hive.pets stats: [numFiles=2, totalSize=96]
OK
Time taken: 0.492 seconds
hive (dvs_hive)> select * from pets;
OK
nemo    fish
fido    dog
rex     dog
paws    cat
wiskers cat
nemo    fish
fido    dog
rex     dog
paws    cat
wiskers cat
Time taken: 0.097 seconds, Fetched: 10 row(s)
hive (dvs_hive)> load data local inpath '/home/cloudera/dvs/pets2.csv' into table  pets;
Loading data to table dvs_hive.pets
Table dvs_hive.pets stats: [numFiles=3, totalSize=104]
OK
Time taken: 0.502 seconds
hive (dvs_hive)> select * from pets;
OK
nemo    fish
fido    dog
rex     dog
paws    cat
wiskers cat
a       b
c       d
nemo    fish
fido    dog
rex     dog
paws    cat
wiskers cat
Time taken: 0.085 seconds, Fetched: 12 row(s)
hive (dvs_hive)> create table emp4mhdfs(empno int,ename string,job string,sal double,comm double,deptno int)row format delimited fields terminated by ',' location '/user/cloudera/emp_dir';
OK
Time taken: 0.11 seconds
hive (dvs_hive)> select * from emp4mhdfs;
OK
7369    SMITH   CLERK   800.0   NULL    20
7499    ALLEN   SALESMAN        1600.0  300.0   30
7521    WARD    SALESMAN        1250.0  500.0   30
7566    JONES   MANAGER 2975.0  NULL    20
7654    MARTIN  SALESMAN        1250.0  1400.0  30
7698    BLAKE   MANAGER 2850.0  NULL    30
7782    CLARK   MANAGER 2450.0  NULL    10
7788    SCOTT   ANALYST 3000.0  NULL    20
7839    KING    PRESIDENT       5000.0  NULL    10
7844    TURNER  SALESMAN        1500.0  0.0     30
7876    ADAMS   CLERK   1100.0  NULL    20
7900    JAMES   CLERK   950.0   NULL    30
7902    FORD    ANALYST 3000.0  NULL    20
7934    MILLER  CLERK   1300.0  NULL    10
1111    Kavya   SE      1500000.0       5000.0  11
2222    Vinu    SSE     160000.0        6000.0  22
3333    abc     Manager 100000.0        2999.0  NULL
NULL    4444            NULL    NULL    NULL
Time taken: 0.091 seconds, Fetched: 18 row(s)
hive (dvs_hive)> create table emp_filter(select * from emp4mhdfs where deptno=30)row format delimited fields terminated by ',';
NoViableAltException(226@[])
        at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.identifier(HiveParser_IdentifiersParser.java:11567)
        at org.apache.hadoop.hive.ql.parse.HiveParser.identifier(HiveParser.java:45101)
        at org.apache.hadoop.hive.ql.parse.HiveParser.columnNameType(HiveParser.java:38697)
        at org.apache.hadoop.hive.ql.parse.HiveParser.columnNameTypeList(HiveParser.java:36899)
        at org.apache.hadoop.hive.ql.parse.HiveParser.createTableStatement(HiveParser.java:5058)
        at org.apache.hadoop.hive.ql.parse.HiveParser.ddlStatement(HiveParser.java:2558)
        at org.apache.hadoop.hive.ql.parse.HiveParser.execStatement(HiveParser.java:1590)
        at org.apache.hadoop.hive.ql.parse.HiveParser.statement(HiveParser.java:1066)
        at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:201)
        at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:166)
        at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:524)
        at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1358)
        at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1475)
        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1287)
        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1277)
        at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:226)
        at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:175)
        at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:389)
        at org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:781)
        at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:699)
        at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:634)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.apache.hadoop.util.RunJar.run(RunJar.java:221)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:136)
FAILED: ParseException line 1:24 cannot recognize input near 'select' '*' 'from' in column specification
hive (dvs_hive)> create table emp_filter(select ename from emp4mhdfs where deptno=30)row format delimited fields terminated by ',';
NoViableAltException(226@[])
        at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.identifier(HiveParser_IdentifiersParser.java:11567)
        at org.apache.hadoop.hive.ql.parse.HiveParser.identifier(HiveParser.java:45101)
        at org.apache.hadoop.hive.ql.parse.HiveParser.columnNameType(HiveParser.java:38697)
        at org.apache.hadoop.hive.ql.parse.HiveParser.columnNameTypeList(HiveParser.java:36899)
        at org.apache.hadoop.hive.ql.parse.HiveParser.createTableStatement(HiveParser.java:5058)
        at org.apache.hadoop.hive.ql.parse.HiveParser.ddlStatement(HiveParser.java:2558)
        at org.apache.hadoop.hive.ql.parse.HiveParser.execStatement(HiveParser.java:1590)
        at org.apache.hadoop.hive.ql.parse.HiveParser.statement(HiveParser.java:1066)
        at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:201)
        at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:166)
        at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:524)
        at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1358)
        at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1475)
        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1287)
        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1277)
        at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:226)
        at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:175)
        at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:389)
        at org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:781)
        at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:699)
        at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:634)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.apache.hadoop.util.RunJar.run(RunJar.java:221)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:136)
FAILED: ParseException line 1:24 cannot recognize input near 'select' 'ename' 'from' in column specification
hive (dvs_hive)> create table emp_filter as select ename from emp4mhdfs where deptno=30;
Query ID = cloudera_20190809222020_1129cc55-847e-4b73-ac8c-a79c6444c167
Total jobs = 3
Launching Job 1 out of 3
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_1565411259536_0001, Tracking URL = http://localhost:8088/proxy/application_1565411259536_0001/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1565411259536_0001
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 0
2019-08-09 22:20:55,428 Stage-1 map = 0%,  reduce = 0%
2019-08-09 22:21:07,547 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 5.36 sec
MapReduce Total cumulative CPU time: 5 seconds 360 msec
Ended Job = job_1565411259536_0001
Stage-4 is selected by condition resolver.
Stage-3 is filtered out by condition resolver.
Stage-5 is filtered out by condition resolver.
Moving data to: hdfs://quickstart.cloudera:8020/user/hive/warehouse/dvs_hive.db/.hive-staging_hive_2019-08-09_22-20-33_877_1633340364948350902-1/-ext-10001
Moving data to: hdfs://quickstart.cloudera:8020/user/hive/warehouse/dvs_hive.db/emp_filter
Table dvs_hive.emp_filter stats: [numFiles=1, numRows=6, totalSize=37, rawDataSize=31]
MapReduce Jobs Launched:
Stage-Stage-1: Map: 1   Cumulative CPU: 5.36 sec   HDFS Read: 4805 HDFS Write: 112 SUCCESS
Total MapReduce CPU Time Spent: 5 seconds 360 msec
OK
Time taken: 35.284 seconds
hive (dvs_hive)> select * from emp_filter
               > ;
OK
ALLEN
WARD
MARTIN
BLAKE
TURNER
JAMES
Time taken: 0.068 seconds, Fetched: 6 row(s)
hive (dvs_hive)> select * from emp4mhdfs;
OK
7369    SMITH   CLERK   800.0   NULL    20
7499    ALLEN   SALESMAN        1600.0  300.0   30
7521    WARD    SALESMAN        1250.0  500.0   30
7566    JONES   MANAGER 2975.0  NULL    20
7654    MARTIN  SALESMAN        1250.0  1400.0  30
7698    BLAKE   MANAGER 2850.0  NULL    30
7782    CLARK   MANAGER 2450.0  NULL    10
7788    SCOTT   ANALYST 3000.0  NULL    20
7839    KING    PRESIDENT       5000.0  NULL    10
7844    TURNER  SALESMAN        1500.0  0.0     30
7876    ADAMS   CLERK   1100.0  NULL    20
7900    JAMES   CLERK   950.0   NULL    30
7902    FORD    ANALYST 3000.0  NULL    20
7934    MILLER  CLERK   1300.0  NULL    10
1111    Kavya   SE      1500000.0       5000.0  11
2222    Vinu    SSE     160000.0        6000.0  22
3333    abc     Manager 100000.0        2999.0  NULL
NULL    4444            NULL    NULL    NULL
Time taken: 0.072 seconds, Fetched: 18 row(s)
hive (dvs_hive)> select * from emp_filter
               > ;
OK
ALLEN
WARD
MARTIN
BLAKE
TURNER
JAMES
Time taken: 0.071 seconds, Fetched: 6 row(s)
hive (dvs_hive)> create table emp_filter2 as select ename from emp4mhdfs where deptno=10;
Query ID = cloudera_20190809222323_64d4b7a5-9358-479f-aab0-e9df3de259f2
Total jobs = 3
Launching Job 1 out of 3
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_1565411259536_0002, Tracking URL = http://localhost:8088/proxy/application_1565411259536_0002/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1565411259536_0002
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 0
2019-08-09 22:24:05,071 Stage-1 map = 0%,  reduce = 0%
2019-08-09 22:24:16,264 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 4.33 sec
MapReduce Total cumulative CPU time: 4 seconds 330 msec
Ended Job = job_1565411259536_0002
Stage-4 is selected by condition resolver.
Stage-3 is filtered out by condition resolver.
Stage-5 is filtered out by condition resolver.
Moving data to: hdfs://quickstart.cloudera:8020/user/hive/warehouse/dvs_hive.db/.hive-staging_hive_2019-08-09_22-23-54_578_8510937136120156684-1/-ext-10001
Moving data to: hdfs://quickstart.cloudera:8020/user/hive/warehouse/dvs_hive.db/emp_filter2
Table dvs_hive.emp_filter2 stats: [numFiles=1, numRows=3, totalSize=18, rawDataSize=15]
MapReduce Jobs Launched:
Stage-Stage-1: Map: 1   Cumulative CPU: 4.33 sec   HDFS Read: 4889 HDFS Write: 94 SUCCESS
Total MapReduce CPU Time Spent: 4 seconds 330 msec
OK
Time taken: 23.243 seconds
hive (dvs_hive)>  select ename from emp_filter where deptno=10;
FAILED: SemanticException [Error 10004]: Line 1:36 Invalid table alias or column reference 'deptno': (possible column names are: ename)
hive (dvs_hive)>  select ename from emp_filter where ename='ALLEN';
OK
ALLEN
Time taken: 0.118 seconds, Fetched: 1 row(s)
hive (dvs_hive)> create table emp_join as select ename from emp_filter,emp_filter2;
FAILED: SemanticException Column ename Found in more than One Tables/Subqueries
hive (dvs_hive)> create table emp_join as select emp_filter.ename,emp_filter2.ename from emp_filter,emp_filter2;
Warning: Map Join MAPJOIN[7][bigTable=emp_filter] in task 'Stage-4:MAPRED' is a cross product
FAILED: SemanticException [Error 10036]: Duplicate column name: ename
hive (dvs_hive)> create table emp_join as select emp_filter2.ename from emp_filter,emp_filter2;
Warning: Map Join MAPJOIN[7][bigTable=emp_filter] in task 'Stage-4:MAPRED' is a cross product
Query ID = cloudera_20190809223030_0bf7da43-52cd-4b7e-82af-8741365c4329
Total jobs = 1

2019-08-09 10:31:02     Dump the side-table for tag: 1 with group count: 1 into file: file:/tmp/cloudera/8c3a0d5d-47b7-4c6e-9469-c0147c8349d9/hive_2019-08-09_22-30-44_627_3256202292557994267-1/-local-10003/HashTable-Stage-4/MapJoin-mapfile11--.hashtable
2019-08-09 10:31:02     Uploaded 1 File to: file:/tmp/cloudera/8c3a0d5d-47b7-4c6e-9469-c0147c8349d9/hive_2019-08-09_22-30-44_627_3256202292557994267-1/-local-10003/HashTable-Stage-4/MapJoin-mapfile11--.hashtable (305 bytes)
2019-08-09 10:31:02     End of local task; Time Taken: 1.674 sec.
Execution completed successfully
MapredLocal task succeeded
Launching Job 1 out of 1
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_1565411259536_0003, Tracking URL = http://localhost:8088/proxy/application_1565411259536_0003/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1565411259536_0003
Hadoop job information for Stage-4: number of mappers: 1; number of reducers: 0
2019-08-09 22:31:13,241 Stage-4 map = 0%,  reduce = 0%
2019-08-09 22:31:20,866 Stage-4 map = 100%,  reduce = 0%, Cumulative CPU 2.82 sec
MapReduce Total cumulative CPU time: 2 seconds 820 msec
Ended Job = job_1565411259536_0003
Moving data to: hdfs://quickstart.cloudera:8020/user/hive/warehouse/dvs_hive.db/emp_join
Table dvs_hive.emp_join stats: [numFiles=1, numRows=18, totalSize=108, rawDataSize=90]
MapReduce Jobs Launched:
Stage-Stage-4: Map: 1   Cumulative CPU: 2.82 sec   HDFS Read: 5702 HDFS Write: 181 SUCCESS
Total MapReduce CPU Time Spent: 2 seconds 820 msec
OK
Time taken: 38.897 seconds
hive (dvs_hive)>
